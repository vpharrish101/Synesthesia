{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Universal backend test file.\n",
    "Place this file in the Synesthesia/ folder and run:\n",
    "\n",
    "    python test_backend.py\n",
    "\n",
    "This tests processing for all emails in data/inbox.json:\n",
    "- categorize_email\n",
    "- action_item_extract\n",
    "- autodraft_reply\n",
    "- summary\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, datetime, pprint\n",
    "import json\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FIX IMPORTS: add project root + backend to Python path\n",
    "# ---------------------------------------------------------\n",
    "try:\n",
    "    # When running as a standard script\n",
    "    ROOT = os.path.abspath(os.path.dirname(__file__))\n",
    "except NameError:\n",
    "    # When running in Jupyter/Interactive mode\n",
    "    ROOT = os.path.abspath(os.getcwd())\n",
    "\n",
    "BACKEND = os.path.join(ROOT, \"backend\")\n",
    "\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, BACKEND)\n",
    "\n",
    "print(\"PROJECT ROOT:\", ROOT)\n",
    "print(\"BACKEND PATH:\", BACKEND)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# IMPORTS from your project\n",
    "# ---------------------------------------------------------\n",
    "from backend.agent.agent_orch import (\n",
    "    categorize_email,\n",
    "    action_item_extract,\n",
    "    autodraft_reply,\n",
    "    summary\n",
    ")\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Helper Functions\n",
    "# ---------------------------------------------------------\n",
    "def header(title: str):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(title)\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "def process_email(email):\n",
    "    \"\"\"\n",
    "    Runs the 4 core agent functions on a single email.\n",
    "    Returns a dictionary of results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        body = email.get(\"body\", \"\")\n",
    "        subject = email.get(\"subject\", \"No Subject\")\n",
    "        email_id = email.get(\"id\")\n",
    "\n",
    "        # Run Agents (LLM calls)\n",
    "        # We use json.loads where possible to format the output nicely, \n",
    "        # but fallback to raw string if the LLM output is messy (e.g. markdown blocks).\n",
    "        \n",
    "        raw_cat = categorize_email(body)\n",
    "        try: category = json.loads(raw_cat)\n",
    "        except: category = raw_cat\n",
    "\n",
    "        raw_action = action_item_extract(body)\n",
    "        try: actions = json.loads(raw_action)\n",
    "        except: actions = raw_action\n",
    "\n",
    "        raw_reply = autodraft_reply(body)\n",
    "        try: reply = json.loads(raw_reply)\n",
    "        except: reply = raw_reply\n",
    "\n",
    "        summ = summary(body)\n",
    "\n",
    "        return {\n",
    "            \"id\": email_id,\n",
    "            \"subject\": subject,\n",
    "            \"category\": category,\n",
    "            \"actions\": actions,\n",
    "            \"summary\": summ.strip(),\n",
    "            \"reply\": reply\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error processing {email.get('id')}: {str(e)}\"}\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# MAIN EXECUTION\n",
    "# ---------------------------------------------------------\n",
    "def run_inbox_dry_run():\n",
    "    inbox_path = os.path.join(ROOT, \"data\", \"email_input.json\")\n",
    "    \n",
    "    if not os.path.exists(inbox_path):\n",
    "        print(f\"\\n[!] ERROR: Inbox file not found at: {inbox_path}\")\n",
    "        # Fallback check for notebook specific pathing\n",
    "        fallback_path = os.path.join(ROOT, \"Synesthesia\", \"data\", \"inbox.json\")\n",
    "        if os.path.exists(fallback_path):\n",
    "             print(f\"[*] Found at fallback path: {fallback_path}\")\n",
    "             inbox_path = fallback_path\n",
    "        else:\n",
    "             return\n",
    "\n",
    "    print(f\"\\n[*] Loading inbox from: {inbox_path}\")\n",
    "    with open(inbox_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        emails = json.load(f)\n",
    "\n",
    "    print(f\"[*] Found {len(emails)} emails. Starting parallel dry run (5 workers)...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Run parallel processing\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_email = {executor.submit(process_email, email): email for email in emails}\n",
    "        \n",
    "        for i, future in enumerate(concurrent.futures.as_completed(future_to_email)):\n",
    "            res = future.result()\n",
    "            results.append(res)\n",
    "            \n",
    "            # Print results immediately as they complete\n",
    "            print(f\"\\n--- [{i+1}/{len(emails)}] Processing ID: {res.get('id')} ---\")\n",
    "            \n",
    "            if \"error\" in res:\n",
    "                print(f\"‚ùå {res['error']}\")\n",
    "            else:\n",
    "                print(f\"üìß Subject:  {res['subject']}\")\n",
    "                \n",
    "                print(f\"üè∑Ô∏è  Category:\")\n",
    "                pp.pprint(res['category'])\n",
    "                \n",
    "                print(f\"‚ö° Actions:\")\n",
    "                pp.pprint(res['actions'])\n",
    "                \n",
    "                print(f\"üìù Summary:\\n{res['summary']}\")\n",
    "                \n",
    "                print(f\"üì® Draft Reply:\")\n",
    "                pp.pprint(res['reply'])\n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"\\n[‚úì] Dry run complete. Processed {len(emails)} emails in {duration:.2f} seconds.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_inbox_dry_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7c0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d4024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "import backend.utils.llm_cfg as llm_cfg\n",
    "import backend.utils.sysprompts as sysprompts\n",
    "from backend.utils import json_parser\n",
    "\n",
    "def classify_intent(user_query: str):\n",
    "    \"\"\"\n",
    "    Run ONLY the intent classifier.\n",
    "    No email context, no categorization, no agents.\n",
    "    \"\"\"\n",
    "    prompts = sysprompts.load_prompts()\n",
    "    intent_prompt = prompts.get(\"sys_intent\")\n",
    "\n",
    "    full_prompt = f\"\"\"\n",
    "{intent_prompt}\n",
    "\n",
    "USER QUESTION:\n",
    "{user_query}\n",
    "\"\"\"\n",
    "\n",
    "    raw_output = llm_cfg.run_llm(full_prompt)\n",
    "    intent_json = json_parser.extract_json(raw_output)\n",
    "\n",
    "    return intent_json.get(\"intent\", \"unknown\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n=== Intent Classification Tester ===\")\n",
    "    print(\"Type a query and press Enter.\")\n",
    "    print(\"Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "\n",
    "        if user_query.lower().strip() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        intent = classify_intent(user_query)\n",
    "        print(f\">>> Extracted Intent: {intent}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure local imports work\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "from backend.agent.agent_orch import orchestrator\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Dummy email to test general queries\n",
    "# ---------------------------------------------------------\n",
    "DUMMY_EMAIL = \"\"\"\n",
    "Hi there,\n",
    "\n",
    "Just checking in about the report you mentioned last week.\n",
    "I didn‚Äôt see any attached file, so I‚Äôm not sure if something was missing\n",
    "or if I misunderstood your previous message.\n",
    "\n",
    "Let me know what you meant.\n",
    "\n",
    "Thanks!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_general_test():\n",
    "    print(\"\\n=== General Question Tester ===\")\n",
    "    print(\"Dummy email loaded.\\n\")\n",
    "    print(\"EMAIL BODY:\")\n",
    "    print(\"--------------------------------\")\n",
    "    print(DUMMY_EMAIL)\n",
    "    print(\"--------------------------------\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nYour Question (or 'exit'): \")\n",
    "\n",
    "        if user_query.lower().strip() in [\"exit\", \"quit\"]:\n",
    "            print(\"\\nExiting tester.\\n\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n>>> Running orchestrator...\\n\")\n",
    "\n",
    "        result = orchestrator(\n",
    "            email_body=DUMMY_EMAIL,\n",
    "            user_question=user_query,\n",
    "            use_rag=False,\n",
    "            history=None\n",
    "        )\n",
    "\n",
    "        print(\"=== RESULT ===\")\n",
    "        print(f\"Intent: {result.get('intent')}\")\n",
    "        print(f\"Raw Output:\\n{result.get('raw')}\")\n",
    "        print(\"==========================\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_general_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f45c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure this file can import agent_orch.py next to it\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "from backend.agent.agent_orch import orchestrator\n",
    "\n",
    "# -------------------------------\n",
    "# Dummy Email for Testing\n",
    "# -------------------------------\n",
    "TEST_EMAIL = \"\"\"\n",
    "Hi Team,\n",
    "\n",
    "This is a reminder that the final build review is scheduled for tomorrow at 3 PM. \n",
    "Please prepare your module summaries before the meeting.\n",
    "\n",
    "Regards,\n",
    "Alex\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------\n",
    "# Test Queries\n",
    "# -------------------------------\n",
    "TEST_QUERIES = [\n",
    "    \"What category is this email?\",\n",
    "    \"What do I need to do?\",\n",
    "    \"Give me a summary.\",\n",
    "    \"Draft a reply.\",\n",
    "    \"Explain this email.\",\n",
    "    \"Search for emails about build reviews.\"\n",
    "]\n",
    "\n",
    "def print_result(intent, result):\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"USER INTENT ‚Üí {intent}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    print(\"RAW OUTPUT:\")\n",
    "    print(result.get(\"raw\"))\n",
    "\n",
    "    if result.get(\"json\"):\n",
    "        print(\"\\nJSON PARSED:\")\n",
    "        print(result.get(\"json\"))\n",
    "\n",
    "    if result.get(\"results\"):\n",
    "        print(\"\\nRAG RESULTS:\")\n",
    "        print(result.get(\"results\"))\n",
    "\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "\n",
    "def run_tests():\n",
    "    print(\"\\n===== AGENT ORCHESTRATOR TEST HARNESS =====\\n\")\n",
    "    print(\"Loaded dummy email:\\n------------------------------------------\")\n",
    "    print(TEST_EMAIL)\n",
    "    print(\"------------------------------------------\\n\")\n",
    "\n",
    "    for q in TEST_QUERIES:\n",
    "        print(f\"\\n>>> USER QUESTION: {q}\")\n",
    "        result = orchestrator(TEST_EMAIL, q)\n",
    "\n",
    "        intent = result.get(\"intent\")\n",
    "        print_result(intent, result)\n",
    "\n",
    "    print(\"\\n===== TESTING COMPLETE =====\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41718644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RAG Pipeline Test Script.\n",
    "Place this in the Synesthesia/ folder and run:\n",
    "    python test_rag.py\n",
    "\n",
    "This script:\n",
    "1. Builds the hybrid index (TF-IDF + ChromaDB) from your MongoDB emails.\n",
    "2. Runs sample search queries to verify retrieval quality.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PATH SETUP (Fixes ModuleNotFoundError)\n",
    "# ---------------------------------------------------------\n",
    "try:\n",
    "    ROOT = os.path.abspath(os.path.dirname(__file__))\n",
    "except NameError:\n",
    "    ROOT = os.path.abspath(os.getcwd())\n",
    "\n",
    "BACKEND = os.path.join(ROOT, \"backend\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, BACKEND)\n",
    "\n",
    "print(f\"[*] Project Root: {ROOT}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# IMPORTS\n",
    "# ---------------------------------------------------------\n",
    "try:\n",
    "    from backend.rag.r import build_hybrid_index, hybrid_search\n",
    "except ImportError as e:\n",
    "    print(f\"\\n[!] Import Error: {e}\")\n",
    "    print(\"Ensure you have installed RAG dependencies:\")\n",
    "    print(\"pip install chromadb sentence-transformers scikit-learn joblib\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# TEST FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def run_rag_test():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üöÄ STARTING RAG ENGINE TEST\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 1. Build Index\n",
    "    print(\"\\n[*] Step 1: Building Hybrid Index...\")\n",
    "    print(\"    (This trains TF-IDF and embeds emails into ChromaDB)\")\n",
    "    \n",
    "    try:\n",
    "        success = build_hybrid_index()\n",
    "        if not success:\n",
    "            print(\"[!] Error: No emails found in MongoDB.\")\n",
    "            print(\"    Please run 'python backend/db/email_orch.py data/inbox.json' first.\")\n",
    "            return\n",
    "        print(\"[‚úì] Indexing complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Critical Error building index: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Run Search Queries\n",
    "    print(\"\\n[*] Step 2: Testing Search Retrieval...\")\n",
    "    \n",
    "    test_queries = [\n",
    "        \"security alert suspicious login\",\n",
    "        \"deadline for compliance training\",\n",
    "        \"lunch meeting plans\",\n",
    "        \"project chimera code review\"\n",
    "    ]\n",
    "\n",
    "    for query in test_queries:\n",
    "        print(f\"\\nüîç Query: '{query}'\")\n",
    "        try:\n",
    "            # Retrieve top 3 results\n",
    "            results = hybrid_search(query, top_k=3)\n",
    "            \n",
    "            if not results:\n",
    "                print(\"   [!] No results returned.\")\n",
    "                continue\n",
    "\n",
    "            for i, doc in enumerate(results):\n",
    "                # Display metadata\n",
    "                doc_id = doc.get('id', 'N/A')\n",
    "                subject = doc.get('subject', 'No Subject')\n",
    "                sender = doc.get('sender', 'Unknown')\n",
    "                \n",
    "                print(f\"   {i+1}. [{doc_id}] {subject} (From: {sender})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   [!] Search failed: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"[‚úì] RAG Test Complete.\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_rag_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3dec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I am an AI language model and do not have the ability to take photographs. However, if you would like me to provide you with a response related to photography or anything else you are interested in discussing, please let me know!\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
